{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import joblib\n",
    "import logging\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Set up logging with a concise format\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Load API keys with validation\n",
    "load_dotenv()\n",
    "OPENWEATHER_API_KEY = os.getenv(\"OPENWEATHER_API_KEY\")\n",
    "GOOGLE_MAPS_API_KEY = os.getenv(\"GOOGLE_MAPS_API_KEY\")\n",
    "\n",
    "if not all([OPENWEATHER_API_KEY, GOOGLE_MAPS_API_KEY]):\n",
    "    logger.error(\"One or both API keys are missing from .env file.\")\n",
    "    raise ValueError(\"API keys are required for OpenWeather and Google Maps.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path='holidify.csv'):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Define weather conditions for simulation (consistent with later mapping)\n",
    "        weather_conditions = [\n",
    "            'Clear', 'Clouds', 'Drizzle', 'Rain', 'Thunderstorm', 'Snow', 'Mist',\n",
    "            'Smoke', 'Haze', 'Dust', 'Fog', 'Sand', 'Ash', 'Squall', 'Tornado'\n",
    "        ]\n",
    "        \n",
    "        # Simulate missing columns with varied values\n",
    "        df['Temperature'] = np.random.uniform(10, 35, size=len(df))  # Realistic temperature range\n",
    "        df['Weather Condition'] = np.random.choice(weather_conditions, size=len(df))\n",
    "        df['Travel Time'] = np.random.uniform(10, 120, size=len(df))  # Minutes\n",
    "        df['User Ratings Total'] = np.random.randint(50, 501, size=len(df))  # Number of ratings\n",
    "        \n",
    "        # Ensure 'Rating' is float and handle potential missing values\n",
    "        df['Rating'] = pd.to_numeric(df['Rating'], errors='coerce').fillna(3.5)\n",
    "        \n",
    "        logger.info(f\"Loaded data with {len(df)} cities and simulated features.\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to load data from {file_path}: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Engineering for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def engineer_features(df):\n",
    "    try:\n",
    "        # Weather quality mapping (consistent with dynamic phase)\n",
    "        weather_map = {\n",
    "            'Clear': 10, 'Clouds': 7, 'Drizzle': 6, 'Rain': 5, 'Thunderstorm': 4,\n",
    "            'Snow': 3, 'Mist': 4, 'Smoke': 3, 'Haze': 4, 'Dust': 3,\n",
    "            'Fog': 4, 'Sand': 3, 'Ash': 3, 'Squall': 4, 'Tornado': 2\n",
    "        }\n",
    "        df['Weather Quality'] = df['Weather Condition'].map(weather_map).fillna(5)\n",
    "        \n",
    "        # Vectorized feature calculations\n",
    "        df['Traffic Level'] = (df['Travel Time'] / 10).clip(0, 10)\n",
    "        df['Temp_Comfort'] = (10 - abs(df['Temperature'] - 24) / 2).clip(0, 10)\n",
    "        \n",
    "        # Compute Destination Score as a function of features\n",
    "        df['Destination Score'] = (\n",
    "            df['Rating'] * 10 + \n",
    "            df['Weather Quality'] + \n",
    "            df['Temp_Comfort'] - \n",
    "            df['Traffic Level'] + \n",
    "            df['User Ratings Total'] / 100\n",
    "        )\n",
    "        \n",
    "        return df\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Feature engineering failed: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_recommendation_models(df, features):\n",
    "    try:\n",
    "        X = df[features]\n",
    "        y = df['Destination Score']\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        \n",
    "        model = RandomForestRegressor(n_estimators=50, random_state=42, n_jobs=-1)\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        score = model.score(X_test_scaled, y_test)\n",
    "        logger.info(f\"Model trained with R^2 score: {score:.2f} on test set (size={len(y_test)})\")\n",
    "        \n",
    "        return model, features, scaler\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Model training failed: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_enhanced_model(model, features, scaler, model_file='travel_model.pkl', features_file='features.pkl', scaler_file='scaler.pkl'):\n",
    "    try:\n",
    "        # Save all components in a single file for simplicity\n",
    "        joblib.dump({'model': model, 'features': features, 'scaler': scaler}, model_file)\n",
    "        logger.info(f\"Model and components saved to {model_file}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to save model to {model_file}: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "API Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_destination_coords(destination):\n",
    "    try:\n",
    "        url = f\"https://maps.googleapis.com/maps/api/geocode/json?address={destination}&key={GOOGLE_MAPS_API_KEY}\"\n",
    "        response = requests.get(url).json()\n",
    "        if response.get('results'):\n",
    "            location = response['results'][0]['geometry']['location']\n",
    "            return location['lat'], location['lng']  # Corrected 'lon' to 'lng'\n",
    "        logger.warning(f\"No coordinates found for {destination}\")\n",
    "        return None, None\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to fetch coordinates for {destination}: {e}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_weather(lat, lon):\n",
    "    try:\n",
    "        url = f\"http://api.openweathermap.org/data/2.5/weather?lat={lat}&lon={lon}&appid={OPENWEATHER_API_KEY}\"\n",
    "        response = requests.get(url).json()\n",
    "        if response.get('cod') == 200:\n",
    "            temp = response['main']['temp'] - 273.15\n",
    "            condition = response['weather'][0]['main']\n",
    "            return {'temp': temp, 'condition': condition}\n",
    "        logger.warning(f\"Weather API failed for lat={lat}, lon={lon}: {response.get('message', 'Unknown error')}\")\n",
    "        return {'temp': 25, 'condition': 'Clear'}\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Weather fetch failed for lat={lat}, lon={lon}: {e}\")\n",
    "        return {'temp': 25, 'condition': 'Clear'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_traffic(origin, destination_coords):\n",
    "    \"\"\"Deprecated: Use batched traffic fetching in engineer_features_dynamic instead.\"\"\"\n",
    "    try:\n",
    "        url = f\"https://maps.googleapis.com/maps/api/distancematrix/json?origins={origin}&destinations={destination_coords}&key={GOOGLE_MAPS_API_KEY}\"\n",
    "        response = requests.get(url).json()\n",
    "        if response.get('rows') and response['rows'][0]['elements']:\n",
    "            element = response['rows'][0]['elements'][0]\n",
    "            if element['status'] == 'OK':\n",
    "                return element['duration']['value'] / 60\n",
    "        logger.warning(f\"Traffic API failed for origin={origin}, dest={destination_coords}\")\n",
    "        return 30\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Traffic fetch failed for origin={origin}, dest={destination_coords}: {e}\")\n",
    "        return 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_top_places(destination):\n",
    "    try:\n",
    "        url = f\"https://maps.googleapis.com/maps/api/place/textsearch/json?query=top+tourism+places+in+{destination}&key={GOOGLE_MAPS_API_KEY}\"\n",
    "        response = requests.get(url).json()\n",
    "        places = response.get('results', [])\n",
    "        if not places:\n",
    "            logger.warning(f\"No tourism places found for {destination}\")\n",
    "        return places[:20]  # Limit to 20 to respect API limits\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to fetch places for {destination}: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dynamic Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def engineer_features_dynamic(places, traffic_origin, weather):\n",
    "    try:\n",
    "        # Batch fetch travel times for all places\n",
    "        place_coords = [f\"{p['geometry']['location']['lat']},{p['geometry']['location']['lng']}\" for p in places]\n",
    "        url = f\"https://maps.googleapis.com/maps/api/distancematrix/json?origins={traffic_origin}&destinations={'|'.join(place_coords)}&key={GOOGLE_MAPS_API_KEY}\"\n",
    "        response = requests.get(url).json()\n",
    "        travel_times = []\n",
    "        if response.get('rows') and response['rows'][0]['elements']:\n",
    "            elements = response['rows'][0]['elements']\n",
    "            travel_times = [e['duration']['value'] / 60 if e['status'] == 'OK' else 30 for e in elements]\n",
    "        else:\n",
    "            logger.warning(f\"Batch traffic API failed for origin={traffic_origin}\")\n",
    "            travel_times = [30] * len(places)\n",
    "        \n",
    "        # Extended weather mapping consistent with training\n",
    "        weather_map = {\n",
    "            'Clear': 10, 'Clouds': 7, 'Drizzle': 6, 'Rain': 5, 'Thunderstorm': 4,\n",
    "            'Snow': 3, 'Mist': 4, 'Smoke': 3, 'Haze': 4, 'Dust': 3,\n",
    "            'Fog': 4, 'Sand': 3, 'Ash': 3, 'Squall': 4, 'Tornado': 2\n",
    "        }\n",
    "        weather_quality = weather_map.get(weather['condition'], 5)\n",
    "        \n",
    "        # Build place data efficiently\n",
    "        place_data = [\n",
    "            {\n",
    "                'Weather Quality': weather_quality,\n",
    "                'Traffic Level': min(10, t / 10),\n",
    "                'Temp_Comfort': max(0, min(10, 10 - abs(weather['temp'] - 24) / 2)),\n",
    "                'Rating': p.get('rating'),\n",
    "                'User Ratings Total': p.get('user_ratings_total'),\n",
    "                'Travel Time': t\n",
    "            }\n",
    "            for p, t in zip(places, travel_times)\n",
    "        ]\n",
    "        \n",
    "        df_places = pd.DataFrame(place_data)\n",
    "        df_places['Rating'] = df_places['Rating'].fillna(df_places['Rating'].mean() if df_places['Rating'].notna().any() else 3.5)\n",
    "        df_places['User Ratings Total'] = df_places['User Ratings Total'].fillna(\n",
    "            df_places['User Ratings Total'].mean() if df_places['User Ratings Total'].notna().any() else 100\n",
    "        )\n",
    "        \n",
    "        return df_places\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Dynamic feature engineering failed: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dynamic Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_smart_recommendations_dynamic(destination, user_location, model, features, scaler, num_recommendations=5):\n",
    "    try:\n",
    "        lat, lon = get_destination_coords(destination)\n",
    "        traffic_origin = f\"{lat},{lon}\" if lat and lon else user_location\n",
    "        weather = fetch_weather(lat, lon) if lat and lon else {'temp': 25, 'condition': 'Clear'}\n",
    "        \n",
    "        places = fetch_top_places(destination)\n",
    "        if not places:\n",
    "            return \"No places found for this destination.\"\n",
    "        \n",
    "        df_places = engineer_features_dynamic(places, traffic_origin, weather)\n",
    "        \n",
    "        # Ensure feature alignment efficiently\n",
    "        missing_features = [f for f in features if f not in df_places.columns]\n",
    "        if missing_features:\n",
    "            df_places = df_places.assign(**{f: 0 for f in missing_features})\n",
    "        \n",
    "        X_scaled = scaler.transform(df_places[features])\n",
    "        predicted_scores = model.predict(X_scaled)\n",
    "        \n",
    "        # Add predictions to places efficiently\n",
    "        for i, place in enumerate(places):\n",
    "            place.update({\n",
    "                'Predicted Score': predicted_scores[i],\n",
    "                'Travel Time': df_places['Travel Time'].iloc[i],\n",
    "                'Weather': weather['condition'],\n",
    "                'Temperature': weather['temp']\n",
    "            })\n",
    "        \n",
    "        top_places = sorted(places, key=lambda x: x['Predicted Score'], reverse=True)[:num_recommendations]\n",
    "        \n",
    "        return pd.DataFrame([\n",
    "            {\n",
    "                'Name': p['name'],\n",
    "                'Rating': p.get('rating', 'N/A'),\n",
    "                'Predicted Score': round(p['Predicted Score'], 2),\n",
    "                'Address': p.get('formatted_address', 'N/A'),\n",
    "                'Types': ', '.join(p.get('types', [])),\n",
    "                'Weather': p['Weather'],\n",
    "                'Temperature': round(p['Temperature'], 1),\n",
    "                'Travel Time (min)': round(p['Travel Time'], 1)\n",
    "            }\n",
    "            for p in top_places\n",
    "        ])\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Recommendation generation failed for {destination}: {e}\")\n",
    "        return \"Error generating recommendations.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-23 12:43:41,107 - INFO - Starting travel recommendation process\n",
      "2025-03-23 12:43:41,322 - INFO - Data loaded successfully from holidify.csv\n",
      "2025-03-23 12:43:41,326 - ERROR - Feature engineering failed: 'Weather Condition'\n",
      "2025-03-23 12:43:41,329 - ERROR - Main process failed: 'Weather Condition'\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pavan\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 3805, in get_loc\n",
      "    return self._engine.get_loc(casted_key)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"index.pyx\", line 167, in pandas._libs.index.IndexEngine.get_loc\n",
      "  File \"index.pyx\", line 196, in pandas._libs.index.IndexEngine.get_loc\n",
      "  File \"pandas\\\\_libs\\\\hashtable_class_helper.pxi\", line 7081, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
      "  File \"pandas\\\\_libs\\\\hashtable_class_helper.pxi\", line 7089, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
      "KeyError: 'Weather Condition'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pavan\\AppData\\Local\\Temp\\ipykernel_20340\\916657476.py\", line 25, in main\n",
      "    df_processed = engineer_features(df)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\pavan\\AppData\\Local\\Temp\\ipykernel_20340\\1141860482.py\", line 9, in engineer_features\n",
      "    df['Weather Quality'] = df['Weather Condition'].map(weather_map).fillna(5)\n",
      "                            ~~^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pavan\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py\", line 4102, in __getitem__\n",
      "    indexer = self.columns.get_loc(key)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pavan\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 3812, in get_loc\n",
      "    raise KeyError(key) from err\n",
      "KeyError: 'Weather Condition'\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import pandas as pd  # ✅ Fix: Import pandas\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def load_data(file_path=\"holidify.csv\"):\n",
    "    \"\"\"Loads travel data from a CSV file.\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)  # ✅ Ensure 'pd' is defined\n",
    "        logger.info(\"Data loaded successfully from %s\", file_path)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to load data from {file_path}: {e}\", exc_info=True)\n",
    "        raise  # Re-raise exception to stop execution\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to run the travel recommendation process.\"\"\"\n",
    "    try:\n",
    "        logger.info(\"Starting travel recommendation process\")\n",
    "        \n",
    "        # Load and process data\n",
    "        df = load_data()\n",
    "        df_processed = engineer_features(df)\n",
    "        \n",
    "        # Define model features\n",
    "        features = ['Weather Quality', 'Traffic Level', 'Temp_Comfort', 'Rating', 'User Ratings Total']\n",
    "        \n",
    "        # Train model\n",
    "        model, features, scaler = train_recommendation_models(df_processed, features)\n",
    "        save_enhanced_model(model, features, scaler)\n",
    "        \n",
    "        # Define user location and destination\n",
    "        user_location = \"48.8566,2.3522\"  # Paris coordinates\n",
    "        destination = \"Paris\"\n",
    "        \n",
    "        # Generate recommendations\n",
    "        recommendations = generate_smart_recommendations_dynamic(destination, user_location, model, features, scaler)\n",
    "        \n",
    "        # Display results\n",
    "        logger.info(\"Top Recommendations:\\n%s\", recommendations)\n",
    "        print(\"Top Recommendations:\")\n",
    "        print(recommendations)\n",
    "\n",
    "        logger.info(\"Process completed successfully\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Main process failed: {e}\", exc_info=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
